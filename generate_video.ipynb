{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0+cu118\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "CUDA device name: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from diffusers.utils import export_to_video\n",
    "from diffusers import LTXPipeline\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "print(\"CUDA device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA device found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615a87a62f7e468eaffbf7ed630c16ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fca7cd7d0e46688a1fc9c62526f48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = LTXPipeline.from_pretrained(\n",
    "    \"D:\\\\huggingface_models\\\\LTX-Video\",\n",
    "    torch_dtype=torch.float16,  # ✅ Use float16 (uses less memory)\n",
    ")\n",
    "\n",
    "pipe.enable_attention_slicing()  # ✅ Reduces VRAM usage\n",
    "pipe.to(\"cuda\")\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (  \n",
    "    \"A stunning Asian woman with long, dark brown hair gracefully dances to a trending Tagalog song. She has a naturally fit and curvy figure with medium-sized breasts, well-proportioned thighs, and a smooth, radiant white skin tone. She wears an elegant, stylish swimsuit that highlights her beauty. The video captures her natural facial expressions, fluid body movements, and detailed skin texture, with professional lighting and a cinematic look.\"  \n",
    ")  \n",
    "\n",
    "negative_prompt = (  \n",
    "    \"Worst quality, low resolution, distorted face, unnatural skin texture, blurry details, stiff movement, unrealistic body proportions, exaggerated features, unnatural lighting, pixelated details, deformed hands or fingers, missing facial details, creepy or horror-like elements.\"  \n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6dcdadd67645ba893ca15ab90f0f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video = pipe(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    width=1024,  \n",
    "    height=576,  # 16:9 ratio for better clarity\n",
    "    num_frames=300,\n",
    "    num_inference_steps=40,\n",
    ").frames  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First frame shape after fixing: (576, 1024, 3)\n",
      "[(576, 1024, 3), (576, 1024, 3), (576, 1024, 3), (576, 1024, 3), (576, 1024, 3)]\n",
      "✅ Video saved successfully as output.mp4!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "# Ensure `video` is properly structured as a list of frames\n",
    "if isinstance(video, list) and len(video) == 1 and isinstance(video[0], list):\n",
    "    video_frames = [np.array(frame) for frame in video[0]]  # Extract frames correctly\n",
    "elif isinstance(video, list):\n",
    "    video_frames = [np.array(frame) for frame in video]\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected video format: {type(video)}\")\n",
    "\n",
    "# Debugging: Check frame shapes\n",
    "print(f\"First frame shape after fixing: {video_frames[0].shape}\")\n",
    "print([frame.shape for frame in video_frames[:5]])  # Should be [(480, 704, 3), ...]\n",
    "\n",
    "# Define output path\n",
    "output_path = \"output.mp4\"\n",
    "\n",
    "# Export video using imageio\n",
    "try:\n",
    "    imageio.mimsave(output_path, video_frames, fps=24)\n",
    "    print(f\"✅ Video saved successfully as {output_path}!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error exporting video: {e}\")\n",
    "    print(type(video), len(video))  # Check video structure\n",
    "    print(video[0].shape if isinstance(video[0], np.ndarray) else type(video[0]))  # Check first element shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
